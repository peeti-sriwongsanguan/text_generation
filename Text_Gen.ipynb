{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae566112-3b05-4982-848e-36477c5ee081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 13:44:11.030186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#@title Imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import textwrap\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5Model, TFT5ForConditionalGeneration\n",
    "from transformers import GPT2Tokenizer, TFOPTForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d89d8a9-cae1-4903-b34a-95bc4ae68e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/peeti_mac/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d7f21-ccab-4b41-9b6e-47cfc46570fa",
   "metadata": {},
   "source": [
    "## Building a Seq2Seq model for Translation using RNNs with and without Attention\n",
    "\n",
    "### Downloading and pre-processing Data\n",
    "\n",
    "\n",
    "Let's get the data. Just like the Keras tutorial, we will use http://www.manythings.org as the source for the parallel corpus, but we will use German.  Machine translation requires sentence pairs for training, that is individual sentences in German and the corresponding sentence in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74b63ee-946b-416d-9923-228021fdbe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archive:  deu-eng.zip',\n",
       " 'replace deu.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n",
       " '(EOF or read error, treating as \"[N]one\" ...)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!curl -O http://www.manythings.org/anki/deu-eng.zip\n",
    "!!unzip deu-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24d1aa-0f7a-426c-a54e-b1f2619585a6",
   "metadata": {},
   "source": [
    "Note these numbers are much smaller than the real world plus I am working on cpu machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22119dda-3128-41f3-aedb-c0634ebf64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100  # Embedding dimensions for vectors and LSTMs.\n",
    "num_samples = 10000  # Number of examples to consider.\n",
    "\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"deu.txt\"\n",
    "\n",
    "# Vocabulary sizes that we'll use:\n",
    "english_vocab_size = 2000\n",
    "german_vocab_size = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bccc87-fc70-4647-b708-f0b4b5795c26",
   "metadata": {},
   "source": [
    "Next we need to format the input by using nltk for the tokenization.\n",
    "\n",
    "using CountVectorizer to create a vocabulary from the most frequent words in each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1a8a66-cd79-4a2d-9bb4-e24a1b0ba601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum source input length:  6\n",
      "Maximum target output length:  10\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "max_input_length = -1\n",
    "max_output_length = -1\n",
    "\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "\n",
    "    tokenized_source_text = nltk.word_tokenize(input_text, language='english')\n",
    "    tokenized_target_text = nltk.word_tokenize(target_text, language='german')\n",
    "\n",
    "    if len(tokenized_source_text) > max_input_length:\n",
    "      max_input_length = len(tokenized_source_text)\n",
    "\n",
    "    if len(tokenized_target_text) > max_output_length:\n",
    "      max_output_length = len(tokenized_target_text)\n",
    "\n",
    "\n",
    "    source_text = (' '.join(tokenized_source_text)).lower()\n",
    "    target_text = (' '.join(tokenized_target_text)).lower()\n",
    "\n",
    "    input_texts.append(source_text)\n",
    "    target_texts.append(target_text)\n",
    "\n",
    "vectorizer_english = CountVectorizer(max_features=english_vocab_size)\n",
    "vectorizer_english.fit(input_texts)\n",
    "vocab_english = vectorizer_english.get_feature_names_out()\n",
    "\n",
    "vectorizer_german = CountVectorizer(max_features=german_vocab_size)\n",
    "vectorizer_german.fit(target_texts)\n",
    "vocab_german = vectorizer_german.get_feature_names_out()\n",
    "\n",
    "print('Maximum source input length: ', max_input_length)\n",
    "print('Maximum target output length: ', max_output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63545a20-9a08-418d-9e86-ea65733a1c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go .', 'hi .']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at a few input words\n",
    "\n",
    "input_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "228b73dc-5c04-4017-be7f-b39aeafa49fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geh .', 'hallo !']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here with german translation \n",
    "\n",
    "target_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee15cbb-cb8b-4ca6-bc59-a2c9616550d8",
   "metadata": {},
   "source": [
    "from our source and target sequences above, we set our max lengths 6 and 11, respectively. As we will add start and end tokens (\\<s> and \\</s>) to our decoder side we will set the respective max lengths to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8779144b-a3ae-41cf-8467-5fb6aec56561",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 6\n",
    "max_decoder_seq_length = 13 #11 + start + end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49cc5d-0d47-4e8a-a889-3d2b1b25b5b6",
   "metadata": {},
   "source": [
    "Next, we create the dictionaries translating between integer ids and tokens for both source (English) and target (German)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381b4f04-da56-48fe-a7bd-b7ac2eb11d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id_vocab_dict = {}\n",
    "source_vocab_id_dict = {}\n",
    "\n",
    "for sid, svocab in enumerate(vocab_english):\n",
    "  source_id_vocab_dict[sid] = svocab\n",
    "  source_vocab_id_dict[svocab] = sid\n",
    "\n",
    "source_id_vocab_dict[english_vocab_size] = \"<unk>\"\n",
    "source_id_vocab_dict[english_vocab_size + 1] = \"<pad>\"\n",
    "\n",
    "source_vocab_id_dict[\"<unk>\"] = english_vocab_size\n",
    "source_vocab_id_dict[\"<pad>\"] = english_vocab_size + 1\n",
    "\n",
    "target_id_vocab_dict = {}\n",
    "target_vocab_id_dict = {}\n",
    "\n",
    "for tid, tvocab in enumerate(vocab_german):\n",
    "  target_id_vocab_dict[tid] = tvocab\n",
    "  target_vocab_id_dict[tvocab] = tid\n",
    "\n",
    "# Add unknown token plus start and end tokens to target language\n",
    "\n",
    "target_id_vocab_dict[german_vocab_size] = \"<unk>\"\n",
    "target_id_vocab_dict[german_vocab_size + 1] = \"<start>\"\n",
    "target_id_vocab_dict[german_vocab_size + 2] = \"<end>\"\n",
    "target_id_vocab_dict[german_vocab_size + 3] = \"<pad>\"\n",
    "\n",
    "target_vocab_id_dict[\"<unk>\"] = german_vocab_size\n",
    "target_vocab_id_dict[\"<start>\"] = german_vocab_size + 1\n",
    "target_vocab_id_dict[\"<end>\"] = german_vocab_size + 2\n",
    "target_vocab_id_dict[\"<pad>\"] = german_vocab_size + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538967a8-ec78-4fd9-b2fc-853a70d78223",
   "metadata": {},
   "source": [
    "Lastly, we need to create the training and test data that will feed into our two models. It is convenient to define a small function for that that also takes care off padding and adding start/end tokens on the decoder side.\n",
    "\n",
    "Notice that we need to create three sequences of vocab ids: inputs to the encoder (starting language), inputs to the decoder (output language, for the preceding tokens in the output sequence) and labels for the decoder (the correct next word to predict at each time step in the output, which is shifted one over from the inputs to the decoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc136ab6-d3b6-4a4e-90a8-7e67f4c653c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_data(texts, \n",
    "                         vocab_id_dict, \n",
    "                         max_length=20, \n",
    "                         type=None,\n",
    "                         train_test_vector=None,\n",
    "                         samples=100000):\n",
    "  \n",
    "  if type == None:\n",
    "    raise ValueError('\\'type\\' is not defined. Please choose from: input_source, input_target, output_target.')\n",
    "  \n",
    "  train_data = []\n",
    "  test_data = []\n",
    "\n",
    "  for text_num, text in enumerate(texts[:samples]):\n",
    "\n",
    "    sentence_ids = []\n",
    "\n",
    "    for token in text.split():\n",
    "\n",
    "      if token in vocab_id_dict.keys():\n",
    "        sentence_ids.append(vocab_id_dict[token])\n",
    "      else:\n",
    "        sentence_ids.append(vocab_id_dict[\"<unk>\"])\n",
    "    \n",
    "    vocab_size = len(vocab_id_dict.keys())\n",
    "    \n",
    "    # Depending on encoder/decoder and input/output, add start/end tokens.\n",
    "    # Then add padding.\n",
    "    \n",
    "    if type == 'input_source':\n",
    "      ids = (sentence_ids + [vocab_size - 1] * max_length)[:max_length]\n",
    "\n",
    "    elif type == 'input_target':\n",
    "      ids = ([vocab_size -3] + sentence_ids + [vocab_size - 2] + [vocab_size - 1] * max_length)[:max_length]\n",
    "\n",
    "    elif type == 'output_target':\n",
    "      ids = (sentence_ids + [vocab_size - 2] + [vocab_size -1] * max_length)[:max_length]\n",
    "\n",
    "    if train_test_vector is not None and not train_test_vector[text_num]:\n",
    "      test_data.append(ids)\n",
    "    else:\n",
    "      train_data.append(ids)\n",
    "\n",
    "\n",
    "  return np.array(train_data), np.array(test_data)\n",
    "\n",
    "\n",
    "train_test_split_vector = (np.random.uniform(size=10000) > 0.2)\n",
    "\n",
    "train_source_input_data, test_source_input_data = convert_text_to_data(input_texts, \n",
    "                                                                       source_vocab_id_dict,\n",
    "                                                                       type='input_source',\n",
    "                                                                       max_length=max_encoder_seq_length,\n",
    "                                                                       train_test_vector=train_test_split_vector)\n",
    "\n",
    "train_target_input_data, test_target_input_data = convert_text_to_data(target_texts,\n",
    "                                                                       target_vocab_id_dict,\n",
    "                                                                       type='input_target',\n",
    "                                                                       max_length=max_decoder_seq_length,\n",
    "                                                                       train_test_vector=train_test_split_vector)\n",
    "\n",
    "train_target_output_data, test_target_output_data = convert_text_to_data(target_texts,\n",
    "                                                                         target_vocab_id_dict,\n",
    "                                                                         type='output_target',\n",
    "                                                                         max_length=max_decoder_seq_length,\n",
    "                                                                         train_test_vector=train_test_split_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3bbca-a52b-416e-99e5-4e1d7425b8ae",
   "metadata": {},
   "source": [
    "Now first we build sqg2seg model without Attention\n",
    "\n",
    "build encoder and the decoder using LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714ae3e9-4ce2-4465-8aa8-9ca891654bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translation_model_no_att(encode_vocab_size, decode_vocab_size, embed_dim):\n",
    "\n",
    "    source_input_no_att = tf.keras.layers.Input(shape=(max_encoder_seq_length,),\n",
    "                                                dtype='int64',\n",
    "                                                name='source_input_no_att')\n",
    "    target_input_no_att = tf.keras.layers.Input(shape=(max_decoder_seq_length,),\n",
    "                                                dtype='int64',\n",
    "                                                name='target_input_no_att')\n",
    "\n",
    "    source_embedding_layer_no_att = tf.keras.layers.Embedding(input_dim=encode_vocab_size,\n",
    "                                                              output_dim=embed_dim,\n",
    "                                                              name='source_embedding_layer_no_att')\n",
    "\n",
    "    target_embedding_layer_no_att  = tf.keras.layers.Embedding(input_dim=decode_vocab_size,\n",
    "                                                               output_dim=embed_dim,\n",
    "                                                               name='target_embedding_layer_no_att')\n",
    "\n",
    "    source_embeddings_no_att = source_embedding_layer_no_att(source_input_no_att)\n",
    "    target_embeddings_no_att = target_embedding_layer_no_att(target_input_no_att)\n",
    "\n",
    "    encoder_lstm_layer_no_att = tf.keras.layers.LSTM(embed_dim, return_sequences=True, return_state=True, name='encoder_lstm_layer_no_att')\n",
    "    encoder_out_no_att, encoder_state_h_no_att, encoder_state_c_no_att = encoder_lstm_layer_no_att(source_embeddings_no_att)\n",
    "\n",
    "    decoder_lstm_layer_no_att = tf.keras.layers.LSTM(embed_dim, return_sequences=True, return_state=False, name='decoder_lstm_layer_no_att')\n",
    "    decoder_lstm_out_no_att = decoder_lstm_layer_no_att(target_embeddings_no_att, [encoder_state_h_no_att, encoder_state_c_no_att])\n",
    "\n",
    "    target_classification_no_att = tf.keras.layers.Dense(decode_vocab_size,\n",
    "                                                         activation='softmax',\n",
    "                                                         name='classification_no_att')(decoder_lstm_out_no_att)\n",
    "\n",
    "    translation_model_no_att = tf.keras.models.Model(inputs=[source_input_no_att, target_input_no_att], outputs=[target_classification_no_att])\n",
    "\n",
    "    translation_model_no_att.compile(optimizer=\"Adam\",\n",
    "                                     loss='sparse_categorical_crossentropy',\n",
    "                                     metrics=['accuracy'])\n",
    "    \n",
    "    return translation_model_no_att\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f29c8a-1ece-4f6c-80ca-73ffdadaf471",
   "metadata": {},
   "source": [
    "instantiate the model above to confirm that we set up the way we like using model.sumary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df8cbe2-fbda-439d-be8f-caecd8cf4700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " source_input_no_att (Input  [(None, 6)]                  0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " target_input_no_att (Input  [(None, 13)]                 0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " source_embedding_layer_no_  (None, 6, 100)               200200    ['source_input_no_att[0][0]'] \n",
      " att (Embedding)                                                                                  \n",
      "                                                                                                  \n",
      " target_embedding_layer_no_  (None, 13, 100)              300400    ['target_input_no_att[0][0]'] \n",
      " att (Embedding)                                                                                  \n",
      "                                                                                                  \n",
      " encoder_lstm_layer_no_att   [(None, 6, 100),             80400     ['source_embedding_layer_no_at\n",
      " (LSTM)                       (None, 100),                          t[0][0]']                     \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " decoder_lstm_layer_no_att   (None, 13, 100)              80400     ['target_embedding_layer_no_at\n",
      " (LSTM)                                                             t[0][0]',                     \n",
      "                                                                     'encoder_lstm_layer_no_att[0]\n",
      "                                                                    [1]',                         \n",
      "                                                                     'encoder_lstm_layer_no_att[0]\n",
      "                                                                    [2]']                         \n",
      "                                                                                                  \n",
      " classification_no_att (Den  (None, 13, 3004)             303404    ['decoder_lstm_layer_no_att[0]\n",
      " se)                                                                [0]']                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 964804 (3.68 MB)\n",
      "Trainable params: 964804 (3.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encode_vocab_size = len(source_id_vocab_dict.keys())\n",
    "decode_vocab_size = len(target_id_vocab_dict.keys())\n",
    "\n",
    "translation_model_no_att = create_translation_model_no_att(encode_vocab_size, decode_vocab_size, embed_dim)\n",
    "\n",
    "translation_model_no_att.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bcd9da8-5ba0-4a36-ae6f-32b07e025c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.2394 - accuracy: 0.9414 - val_loss: 0.9294 - val_accuracy: 0.8659\n",
      "Epoch 2/40\n",
      "252/252 [==============================] - 8s 32ms/step - loss: 0.2294 - accuracy: 0.9442 - val_loss: 0.9337 - val_accuracy: 0.8650\n",
      "Epoch 3/40\n",
      "252/252 [==============================] - 8s 32ms/step - loss: 0.2187 - accuracy: 0.9462 - val_loss: 0.9388 - val_accuracy: 0.8638\n",
      "Epoch 4/40\n",
      "252/252 [==============================] - 8s 34ms/step - loss: 0.2100 - accuracy: 0.9478 - val_loss: 0.9371 - val_accuracy: 0.8655\n",
      "Epoch 5/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.2007 - accuracy: 0.9507 - val_loss: 0.9373 - val_accuracy: 0.8659\n",
      "Epoch 6/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1918 - accuracy: 0.9522 - val_loss: 0.9428 - val_accuracy: 0.8664\n",
      "Epoch 7/40\n",
      "252/252 [==============================] - 9s 37ms/step - loss: 0.1833 - accuracy: 0.9538 - val_loss: 0.9468 - val_accuracy: 0.8663\n",
      "Epoch 8/40\n",
      "252/252 [==============================] - 8s 32ms/step - loss: 0.1751 - accuracy: 0.9556 - val_loss: 0.9512 - val_accuracy: 0.8663\n",
      "Epoch 9/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1688 - accuracy: 0.9566 - val_loss: 0.9538 - val_accuracy: 0.8677\n",
      "Epoch 10/40\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.1610 - accuracy: 0.9580 - val_loss: 0.9582 - val_accuracy: 0.8669\n",
      "Epoch 11/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1545 - accuracy: 0.9594 - val_loss: 0.9627 - val_accuracy: 0.8670\n",
      "Epoch 12/40\n",
      "252/252 [==============================] - 8s 34ms/step - loss: 0.1484 - accuracy: 0.9603 - val_loss: 0.9658 - val_accuracy: 0.8666\n",
      "Epoch 13/40\n",
      "252/252 [==============================] - 8s 34ms/step - loss: 0.1430 - accuracy: 0.9617 - val_loss: 0.9719 - val_accuracy: 0.8670\n",
      "Epoch 14/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1378 - accuracy: 0.9630 - val_loss: 0.9751 - val_accuracy: 0.8667\n",
      "Epoch 15/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.1323 - accuracy: 0.9635 - val_loss: 0.9782 - val_accuracy: 0.8676\n",
      "Epoch 16/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1276 - accuracy: 0.9640 - val_loss: 0.9796 - val_accuracy: 0.8679\n",
      "Epoch 17/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.1230 - accuracy: 0.9653 - val_loss: 0.9861 - val_accuracy: 0.8665\n",
      "Epoch 18/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1190 - accuracy: 0.9659 - val_loss: 0.9874 - val_accuracy: 0.8669\n",
      "Epoch 19/40\n",
      "252/252 [==============================] - 9s 37ms/step - loss: 0.1150 - accuracy: 0.9663 - val_loss: 0.9950 - val_accuracy: 0.8665\n",
      "Epoch 20/40\n",
      "252/252 [==============================] - 10s 40ms/step - loss: 0.1111 - accuracy: 0.9669 - val_loss: 0.9959 - val_accuracy: 0.8669\n",
      "Epoch 21/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.1085 - accuracy: 0.9672 - val_loss: 0.9971 - val_accuracy: 0.8670\n",
      "Epoch 22/40\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 1.0116 - val_accuracy: 0.8667\n",
      "Epoch 23/40\n",
      "252/252 [==============================] - 11s 44ms/step - loss: 0.1013 - accuracy: 0.9680 - val_loss: 1.0079 - val_accuracy: 0.8667\n",
      "Epoch 24/40\n",
      "252/252 [==============================] - 10s 38ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 1.0139 - val_accuracy: 0.8658\n",
      "Epoch 25/40\n",
      "252/252 [==============================] - 10s 40ms/step - loss: 0.0951 - accuracy: 0.9693 - val_loss: 1.0208 - val_accuracy: 0.8663\n",
      "Epoch 26/40\n",
      "252/252 [==============================] - 9s 38ms/step - loss: 0.0930 - accuracy: 0.9692 - val_loss: 1.0215 - val_accuracy: 0.8673\n",
      "Epoch 27/40\n",
      "252/252 [==============================] - 9s 36ms/step - loss: 0.0905 - accuracy: 0.9695 - val_loss: 1.0288 - val_accuracy: 0.8666\n",
      "Epoch 28/40\n",
      "252/252 [==============================] - 9s 37ms/step - loss: 0.0885 - accuracy: 0.9696 - val_loss: 1.0357 - val_accuracy: 0.8665\n",
      "Epoch 29/40\n",
      "252/252 [==============================] - 10s 39ms/step - loss: 0.0866 - accuracy: 0.9703 - val_loss: 1.0378 - val_accuracy: 0.8657\n",
      "Epoch 30/40\n",
      "252/252 [==============================] - 10s 40ms/step - loss: 0.0838 - accuracy: 0.9705 - val_loss: 1.0417 - val_accuracy: 0.8665\n",
      "Epoch 31/40\n",
      "252/252 [==============================] - 10s 39ms/step - loss: 0.0821 - accuracy: 0.9705 - val_loss: 1.0457 - val_accuracy: 0.8667\n",
      "Epoch 32/40\n",
      "252/252 [==============================] - 10s 39ms/step - loss: 0.0813 - accuracy: 0.9708 - val_loss: 1.0458 - val_accuracy: 0.8672\n",
      "Epoch 33/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.0791 - accuracy: 0.9709 - val_loss: 1.0538 - val_accuracy: 0.8666\n",
      "Epoch 34/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.0779 - accuracy: 0.9712 - val_loss: 1.0566 - val_accuracy: 0.8663\n",
      "Epoch 35/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.0766 - accuracy: 0.9713 - val_loss: 1.0606 - val_accuracy: 0.8669\n",
      "Epoch 36/40\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.0746 - accuracy: 0.9707 - val_loss: 1.0724 - val_accuracy: 0.8661\n",
      "Epoch 37/40\n",
      "252/252 [==============================] - 9s 36ms/step - loss: 0.0728 - accuracy: 0.9714 - val_loss: 1.0716 - val_accuracy: 0.8665\n",
      "Epoch 38/40\n",
      "252/252 [==============================] - 9s 36ms/step - loss: 0.0715 - accuracy: 0.9718 - val_loss: 1.0765 - val_accuracy: 0.8671\n",
      "Epoch 39/40\n",
      "252/252 [==============================] - 12s 49ms/step - loss: 0.0708 - accuracy: 0.9715 - val_loss: 1.0724 - val_accuracy: 0.8660\n",
      "Epoch 40/40\n",
      "252/252 [==============================] - 12s 48ms/step - loss: 0.0701 - accuracy: 0.9712 - val_loss: 1.0741 - val_accuracy: 0.8666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb28d5a67f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_model_no_att.fit(x=[train_source_input_data, train_target_input_data],\n",
    "                             y=train_target_output_data,\n",
    "                             validation_data=([test_source_input_data, test_target_input_data],\n",
    "                                              test_target_output_data),\n",
    "                             epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a023f-6087-4ea7-849d-75689e7d2852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
